network init start

hyperparameters
init_weight_range 0.000000 ,xavier
learning_rate 0.000025
lambda1 0.000000
lambda2 0.000000
dropout 0.400000
minibatch size 32

         CONVOLUTION  [  688   432     3] [    3     3    16] [  688   432    16] [       432         16][ 133152768]
                RELU  [  688   432    16] [    1     1     1] [  688   432    16] [         0          0][   9510912]
         MAX POOLING  [  688   432    16] [    2     2     1] [  344   216    16] [         0          0][   9510912]
   DENSE CONVOLUTION  [  344   216    16] [    3     3     8] [  344   216    24] [      1152          8][  86192640]
                RELU  [  344   216    24] [    1     1     1] [  344   216    24] [         0          0][   3566592]
   DENSE CONVOLUTION  [  344   216    24] [    3     3     8] [  344   216    32] [      1728          8][ 128991744]
                RELU  [  344   216    32] [    1     1     1] [  344   216    32] [         0          0][   4755456]
   DENSE CONVOLUTION  [  344   216    32] [    3     3     8] [  344   216    40] [      2304          8][ 171790848]
                RELU  [  344   216    40] [    1     1     1] [  344   216    40] [         0          0][   5944320]
   DENSE CONVOLUTION  [  344   216    40] [    3     3     8] [  344   216    48] [      2880          8][ 214589952]
                RELU  [  344   216    48] [    1     1     1] [  344   216    48] [         0          0][   7133184]
         CONVOLUTION  [  344   216    48] [    1     1    32] [  344   216    32] [      1536         32][ 116508672]
                RELU  [  344   216    32] [    1     1     1] [  344   216    32] [         0          0][   4755456]
         MAX POOLING  [  344   216    32] [    2     2     1] [  172   108    32] [         0          0][   4755456]
   DENSE CONVOLUTION  [  172   108    32] [    3     3     8] [  172   108    40] [      2304          8][  42947712]
                RELU  [  172   108    40] [    1     1     1] [  172   108    40] [         0          0][   1486080]
   DENSE CONVOLUTION  [  172   108    40] [    3     3     8] [  172   108    48] [      2880          8][  53647488]
                RELU  [  172   108    48] [    1     1     1] [  172   108    48] [         0          0][   1783296]
   DENSE CONVOLUTION  [  172   108    48] [    3     3     8] [  172   108    56] [      3456          8][  64347264]
                RELU  [  172   108    56] [    1     1     1] [  172   108    56] [         0          0][   2080512]
   DENSE CONVOLUTION  [  172   108    56] [    3     3     8] [  172   108    64] [      4032          8][  75047040]
                RELU  [  172   108    64] [    1     1     1] [  172   108    64] [         0          0][   2377728]
         CONVOLUTION  [  172   108    64] [    1     1    32] [  172   108    32] [      2048         32][  38638080]
                RELU  [  172   108    32] [    1     1     1] [  172   108    32] [         0          0][   1188864]
         MAX POOLING  [  172   108    32] [    2     2     1] [   86    54    32] [         0          0][   1188864]
         CONVOLUTION  [   86    54    32] [    3     3    64] [   86    54    64] [     18432         64][  85895424]
                RELU  [   86    54    64] [    1     1     1] [   86    54    64] [         0          0][    594432]
             DROPOUT  [   86    54    64] [    1     1     1] [   86    54    64] [         0          0][    594432]
         CONVOLUTION  [   86    54    64] [    8     8     4] [   86    54     4] [     16384          4][  76105872]

input_geometry  [688 432 3]
output_geometry [86 54 4]
network flops operations 1349081984 FLOPS, 1.349082 GFLOPS
init DONE

network destructor done
