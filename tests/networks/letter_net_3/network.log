network init start

hyperparameters
init_weight_range 0.000000 ,xavier
learning_rate 0.000050
lambda1 0.000000
lambda2 0.000000
dropout 0.400000
minibatch size 32

   DENSE CONVOLUTION  [  416   272     3] [    3     3     8] [  416   272    11] [       216          8][  25346048]
                RELU  [  416   272    11] [    1     1     1] [  416   272    11] [         0          0][   2489344]
   DENSE CONVOLUTION  [  416   272    11] [    3     3     8] [  416   272    19] [       792          8][  90521600]
                RELU  [  416   272    19] [    1     1     1] [  416   272    19] [         0          0][   4299776]
   DENSE CONVOLUTION  [  416   272    19] [    3     3     8] [  416   272    27] [      1368          8][ 155697152]
                RELU  [  416   272    27] [    1     1     1] [  416   272    27] [         0          0][   6110208]
   DENSE CONVOLUTION  [  416   272    27] [    3     3     8] [  416   272    35] [      1944          8][ 220872704]
                RELU  [  416   272    35] [    1     1     1] [  416   272    35] [         0          0][   7920640]
         CONVOLUTION  [  416   272    35] [    1     1    32] [  416   272    32] [      1120         32][ 130351104]
                RELU  [  416   272    32] [    1     1     1] [  416   272    32] [         0          0][   7241728]
         MAX POOLING  [  416   272    32] [    2     2     1] [  208   136    32] [         0          0][   7241728]
   DENSE CONVOLUTION  [  208   136    32] [    3     3     8] [  208   136    40] [      2304          8][  65401856]
                RELU  [  208   136    40] [    1     1     1] [  208   136    40] [         0          0][   2263040]
   DENSE CONVOLUTION  [  208   136    40] [    3     3     8] [  208   136    48] [      2880          8][  81695744]
                RELU  [  208   136    48] [    1     1     1] [  208   136    48] [         0          0][   2715648]
   DENSE CONVOLUTION  [  208   136    48] [    3     3     8] [  208   136    56] [      3456          8][  97989632]
                RELU  [  208   136    56] [    1     1     1] [  208   136    56] [         0          0][   3168256]
   DENSE CONVOLUTION  [  208   136    56] [    3     3     8] [  208   136    64] [      4032          8][ 114283520]
                RELU  [  208   136    64] [    1     1     1] [  208   136    64] [         0          0][   3620864]
         CONVOLUTION  [  208   136    64] [    1     1    32] [  208   136    32] [      2048         32][  58839040]
                RELU  [  208   136    32] [    1     1     1] [  208   136    32] [         0          0][   1810432]
         MAX POOLING  [  208   136    32] [    2     2     1] [  104    68    32] [         0          0][   1810432]
         CONVOLUTION  [  104    68    32] [    3     3    64] [  104    68    64] [     18432         64][ 130803712]
             DROPOUT  [  104    68    64] [    1     1     1] [  104    68    64] [         0          0][    905216]
         CONVOLUTION  [  104    68    64] [    8     8     3] [  104    68     3] [     12288          3][  86921952]

input_geometry  [416 272 3]
output_geometry [104 68 3]
network flops operations 1310321408 FLOPS, 1.310321 GFLOPS
init DONE

network destructor done
